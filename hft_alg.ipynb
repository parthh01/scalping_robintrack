{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "#from alpaca_trade_api import StreamConn\n",
    "import websocket, json, asyncio, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller,kpss\n",
    "from statsmodels.tools.eval_measures import mse\n",
    "import warnings\n",
    "import tensorflow as tf \n",
    "import statsmodels.api as sm\n",
    "from pulp import LpVariable,LpProblem,LpMinimize,value\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> The Strategy: </h1> \n",
    "<p> The strategy chooses a high volume mean reverting stock(using ADF and KPSS) from the previous day's quote data and trains an NN to determine the mean price change within the next time step, if the delta change is above threshold, buy/sell accordingly. Trading occurs during specific windows: 9am to 11:00 pm and  1pm to 3pm</p>\n",
    "\n",
    "<h4> Correction: Trade SPY by default</h4>\n",
    "\n",
    "<ol> \n",
    "    <strong> Logic </strong> \n",
    "    <li>loop through high volume stocks list: determine stationarity via ADF and KPSS. Then determine backtested accuracy of NN forecasting mean price change within forecast window (on validation set)   </li>\n",
    "    <li> during trading hours: monitor and forecast price change with every new incoming quote, if abs(mean price change) > 0.2 ticks, buy/sell with take profit accordingly </li> \n",
    "    <li> close any open positions at end of trading session </li> \n",
    "    \n",
    "</ol>\n",
    "\n",
    "<ul> <strong>  NN Architecture: </strong> \n",
    "    <li> hyperparameters:- forecast window: k,lag window L, neurons, LSTM/FC layers (previous n days data (n = 2)  </li> \n",
    "    <li> X :-  (m x 3) features: 1. rolling_sum(oi/bid_ask_spread) over lag window, 2. rolling_sum(oir/bid_ask_spread), 3. mpb/bid_ask_spread </li> \n",
    "    <li> Y :- (1 x m) forecast price over forecast window </li> \n",
    "</ul> \n",
    "\n",
    "\n",
    "reference: https://pdfs.semanticscholar.org/cf7e/9d9960be215cbc5a0b9f39d4c50879568be3.pdf\n",
    "\n",
    "<h2> Formulas: </h2>\n",
    "\n",
    "\n",
    "Order Imbalance as: \n",
    "\n",
    "<img src=\"images/voi_imbalance.png\" width=\"500\"/>\n",
    "\n",
    "Measure Volume Order imbalance ratio as: \n",
    "\n",
    "<img src=\"images/oir.png\" width=\"200\"/>\n",
    "\n",
    "Develop Linear Model from previous Day's prices with: \n",
    "<img src=\"images/linear_model.png\" width=\"500\"/>\n",
    "\n",
    "mean price basis \n",
    "<img src=\"images/mpb.png\" width=\"500\"/>\n",
    "<img src=\"images/mpb_explanation.png\" width=\"500\"/>\n",
    "\n",
    "Average Trade Price: \n",
    "<img src=\"images/tp.png\" width=\"500\"/>\n",
    "\n",
    "<p> <strong> Important note: volume is cumulative volume </strong> </p>\n",
    "\n",
    "default values for linear model: k=5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def on_open(ws):\n",
    "    print(\"stream connection opened\")\n",
    "    auth_data = {\n",
    "        \"action\": \"auth\",\n",
    "        \"params\": api_key_id\n",
    "    }\n",
    "\n",
    "    ws.send(json.dumps(auth_data))\n",
    "\n",
    "    channel_data = {\n",
    "        \"action\": \"subscribe\",\n",
    "        \"params\": 'Q.SPY'\n",
    "    }\n",
    "    ws.send(json.dumps(channel_data))\n",
    "    \n",
    "def on_message(ws,data):\n",
    "    data = json.loads(data)\n",
    "    for quote in data:\n",
    "        for key,value in quote.items():\n",
    "            if key == 't': value = time.strftime('%Y-%m-%d %H:%M:%S.%Z', time.localtime(value/1000))\n",
    "            print('{}: {} '.format(key,value))\n",
    "            \n",
    "def on_close(ws):\n",
    "    print('closed streaming_connection')\n",
    "\n",
    "socket = \"wss://alpaca.socket.polygon.io/stocks\"\n",
    "\n",
    "ws = websocket.WebSocketApp(socket, on_open=on_open, on_message=on_message, on_close=on_close)\n",
    "ws.run_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' sample quote '''\n",
    "ev: Q #quote \n",
    "sym: SPY #ticker \n",
    "c: 1 # idk\n",
    "bx: 12 # bid exchange \n",
    "ax: 11  #ask exchange \n",
    "bp: 301.52 #bid price\n",
    "ap: 301.54 # ask price \n",
    "bs: 10 #bid size \n",
    "as: 4  #ask size \n",
    "t: 2020-06-11 15:01:55 # time to the nearest second \n",
    "z: 1 # tape ID \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self,layers = [3,1]):\n",
    "        self.dimensions = layers\n",
    "        self.model = tf.keras.Sequential()\n",
    "        for layer in layers[:-1]: \n",
    "            self.model.add(tf.keras.layers.Dense(layer))\n",
    "        self.model.add(tf.keras.layers.Dense(layers[-1]))\n",
    "        self.loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "        self.model.compile(optimizer = 'adam',\n",
    "              loss=self.loss_fn,\n",
    "             metrics = ['accuracy'])\n",
    "        \n",
    "    def train_model(self,X_train,Y_train,num_epochs):\n",
    "        self.model.fit(X_train,Y_train,epochs = num_epochs)\n",
    "        \n",
    "    def evaluate_model(self,X_test,Y_test):\n",
    "        return self.model.evaluate(X_test,Y_test,verbose =2) # returns test_loss,test_acc\n",
    "\n",
    "    \n",
    "def backtest_daterange(end_date,lookback):\n",
    "    end_date = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    return [(end_date - datetime.timedelta(days=i)).strftime('%Y-%m-%d') for i in reversed(range(lookback)) if (end_date - datetime.timedelta(days=i)).isoweekday() in range(1,6)] \n",
    "\n",
    "def turnover_and_mtp_data(asset,date):\n",
    "    data =  api.polygon.historic_trades_v2(asset, date).df.drop(\n",
    "    ['participant_timestamp',\n",
    "    'trf_timestamp',\n",
    "    'sequence_number',\n",
    "    'id',\n",
    "    'exchange',\n",
    "    'conditions',\n",
    "    'tape'],\n",
    "    axis=1).rename(columns = {'size': 'vol'})\n",
    "    turnover = pd.DataFrame()\n",
    "    turnover['volume'] = data.vol.resample('1S').sum()\n",
    "    turnover['price'] = data.price.resample('1S').mean()\n",
    "    turnover['turnover'] = turnover['price'] * turnover['volume']\n",
    "    turnover['mtp'] = (turnover['turnover'] - turnover['turnover'].shift(1))/(turnover['volume'] - turnover['volume'].shift(1))\n",
    "    turnover.loc[turnover['volume'] == turnover['volume'].shift(1),'mtp'] = turnover.loc[turnover['volume'] == turnover['volume'].shift(1),'mtp'].shift(1)\n",
    "    return turnover\n",
    "\n",
    "\n",
    "def get_historic_quotes(asset,date):\n",
    "    df = api.polygon.historic_quotes_v2(asset,date).df.sort_index().drop(\n",
    "        ['trf_timestamp',\n",
    "        'sequence_number',\n",
    "        'conditions',\n",
    "        'indicators',\n",
    "        'bid_exchange',\n",
    "        'ask_exchange',\n",
    "        'tape',\n",
    "        'participant_timestamp'], \n",
    "        axis = 1)\n",
    "    #sample_df = df.resample('1min').mean()\n",
    "    #df.index = df.index.strftime('%m/%d/%Y %H:%M:%S')\n",
    "    #sample_df.index = sample_df.index.strftime('%m/%d/%Y %H:%M:%S')\n",
    "    #print(df)\n",
    "    #print(sample_df)\n",
    "    resampled = pd.DataFrame()\n",
    "    resampled['bid_price'] = df.bid_price.resample('1S').mean()\n",
    "    resampled['bid_size'] = df.bid_size.resample('1S').sum()\n",
    "    resampled['ask_price'] = df.ask_price.resample('1S').mean()\n",
    "    resampled['ask_size'] = df.ask_size.resample('1S').sum()\n",
    "    resampled = resampled.join(turnover_and_mtp_data(asset,date)['mtp'])\n",
    "    resampled['mtp'].iloc[0] = (resampled['bid_price'].iloc[0] + resampled['ask_price'].iloc[0])/2 # manuallly set mtp at t=0 \n",
    "    return resampled.dropna()\n",
    "\n",
    "#spy_1 = get_historic_quotes('SPY','2020-06-11')\n",
    "#print(spy_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_training_data(asset,date,forecast_window = 20,lag = 5,plot_results = False):\n",
    "    #1. rolling_sum(oi/bid_ask_spread) over lag window, 2. rolling_sum(oir/bid_ask_spread), 3. mpb/bid_ask_spread\n",
    "    qdf = get_historic_quotes(asset,date)\n",
    "    spread = qdf['ask_price'] - qdf['bid_price']\n",
    "    qdf['dVb'] = qdf['bid_size'].copy()\n",
    "    qdf.loc[qdf['bid_price'] < qdf['bid_price'].shift(1),'dVb'] = 0\n",
    "    qdf.loc[qdf['bid_price'] == qdf['bid_price'].shift(1),'dVb'] = qdf['bid_size'] - qdf['bid_size'].shift(1)\n",
    "    qdf['dVa'] = qdf['ask_size'].copy()\n",
    "    qdf.loc[qdf['ask_price'] > qdf['ask_price'].shift(1),'dVa'] = 0\n",
    "    qdf.loc[qdf['ask_price'] == qdf['ask_price'].shift(1),'dVa'] = qdf['ask_size'] - qdf['ask_size'].shift(1)\n",
    "    imbalance = qdf['dVb'] - qdf['dVa']\n",
    "    mid_price = (qdf['bid_price'] + qdf['ask_price'])/2\n",
    "    mid_price_basis = qdf['mtp'] - 0.5*(mid_price.shift(1) + mid_price)\n",
    "    qdf['mpb'] = mid_price_basis\n",
    "    qdf['imbalance'] = imbalance\n",
    "    ir = (qdf['dVb'] - qdf['dVa'])/(qdf['dVb'] + qdf['dVa'])\n",
    "    qdf['imbalance_over_spread'] = imbalance/spread\n",
    "    qdf['imbalance_ratio_over_spread'] = ir/spread\n",
    "    qdf['mpb_over_spread'] = mid_price_basis/spread\n",
    "    qdf['forecast_mid_price'] = (mid_price.iloc[::-1].rolling(forecast_window).sum() - forecast_window*mid_price)/forecast_window\n",
    "    qdf = qdf.drop(['dVb','dVa','mtp'],axis = 1)\n",
    "    if plot_results: \n",
    "        plt.figure(0).suptitle('mpb vs actual price change')\n",
    "        plt.scatter(x = qdf['mpb'],y =qdf['forecast_mid_price'])\n",
    "        plt.figure(1).suptitle('order_imbalance')\n",
    "        plt.plot(qdf['imbalance'].tolist(), color = 'red')\n",
    "        plt.figure(2).suptitle('average price change')\n",
    "        plt.plot(qdf['forecast_mid_price'].tolist(), color ='green')\n",
    "        plt.figure(3).suptitle('mid price basis')\n",
    "        plt.plot(qdf['mpb'].tolist(),color = 'orange')\n",
    "        plt.show()\n",
    "    return qdf.replace([np.inf, -np.inf], np.nan).dropna() # still have to drop the imbalance and mbp before feeeding to NN\n",
    "\n",
    "def is_series_stationary(series,is_df = True):\n",
    "    if is_df: series = series.to_numpy().reshape((-1,1))\n",
    "    try: \n",
    "        adf_result = adfuller(series)\n",
    "        kpss_result = kpss(series)\n",
    "    except: \n",
    "        return False\n",
    "    is_adf_stationary = adf_result[0] < adf_result[4]['1%']\n",
    "    is_kpss_stationary = kpss_result[0] < kpss_result[3]['10%']\n",
    "    if is_adf_stationary and is_kpss_stationary: \n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def backtest_stationarity(asset,end_date,lookback,print_errors = False):\n",
    "    logs = []\n",
    "    num_days_mean_reverting = 0 \n",
    "    daterange = backtest_daterange(end_date,lookback)\n",
    "    backtest_len = len(daterange)\n",
    "    for date in daterange:\n",
    "        try: \n",
    "            results = get_training_data(asset,date)\n",
    "        except: \n",
    "            if print_errors: print('error getting training_data for {}'.format(date))\n",
    "            backtest_len -= 1 \n",
    "            continue\n",
    "        if is_series_stationary(results['imbalance']) and is_series_stationary(results['forecast_mid_price']):\n",
    "            logs.append(results)\n",
    "            num_days_mean_reverting += 1 \n",
    "    print('{} found to be mean reverting {}% of the time from {} to {}'.format(asset,num_days_mean_reverting*100/backtest_len,daterange[0],daterange[-1]))    \n",
    "    return logs \n",
    "        \n",
    "    \n",
    "def prepare_nn_data(df):\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    X = df[['imbalance_over_spread','imbalance_ratio_over_spread','mpb_over_spread']].to_numpy()\n",
    "    Y = df['forecast_mid_price'].to_numpy().reshape((-1,1)) \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = backtest_stationarity('GDX','2020-06-09',30)\n",
    "print([datetime.datetime.strftime(df.index[0],'%Y-%m-%d') for df in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           bid_price  bid_size  ask_price  ask_size  \\\n",
      "sip_timestamp                                                         \n",
      "2020-05-12 08:22:58-04:00  34.160000        12  34.223333         8   \n",
      "2020-05-12 08:27:32-04:00  34.060000         8  34.150000        10   \n",
      "2020-05-12 08:36:31-04:00  34.078000        41  34.120000         5   \n",
      "2020-05-12 09:25:44-04:00  34.221429        23  34.260000        73   \n",
      "2020-05-12 09:25:56-04:00  34.260000         7  34.280000        51   \n",
      "...                              ...       ...        ...       ...   \n",
      "2020-05-12 09:52:28-04:00  34.273415       625  34.281951      1894   \n",
      "2020-05-12 09:52:31-04:00  34.270000       545  34.280000      1633   \n",
      "2020-05-12 09:52:32-04:00  34.270000       209  34.280000       635   \n",
      "2020-05-12 09:52:35-04:00  34.270000        21  34.280000       302   \n",
      "2020-05-12 09:52:40-04:00  34.260000       571  34.270000       231   \n",
      "\n",
      "                                    mpb  imbalance  imbalance_over_spread  \\\n",
      "sip_timestamp                                                               \n",
      "2020-05-12 08:22:58-04:00  6.357388e-03        4.0              63.157895   \n",
      "2020-05-12 08:27:32-04:00 -5.096491e-02      -10.0            -111.111111   \n",
      "2020-05-12 08:36:31-04:00  1.800000e-02       36.0             857.142857   \n",
      "2020-05-12 09:25:44-04:00  7.074340e-02       23.0             596.296296   \n",
      "2020-05-12 09:25:56-04:00  1.464286e-02        7.0             350.000000   \n",
      "...                                 ...        ...                    ...   \n",
      "2020-05-12 09:52:28-04:00 -2.174476e-02    -1894.0         -221868.571429   \n",
      "2020-05-12 09:52:31-04:00  2.470658e-03    -1633.0         -163300.000000   \n",
      "2020-05-12 09:52:32-04:00 -3.737374e-03      209.0           20900.000000   \n",
      "2020-05-12 09:52:35-04:00  5.156250e-03       21.0            2100.000000   \n",
      "2020-05-12 09:52:40-04:00  1.421085e-14     -231.0          -23100.000000   \n",
      "\n",
      "                           imbalance_ratio_over_spread  mpb_over_spread  \\\n",
      "sip_timestamp                                                             \n",
      "2020-05-12 08:22:58-04:00                     3.157895     1.003798e-01   \n",
      "2020-05-12 08:27:32-04:00                   -11.111111    -5.662768e-01   \n",
      "2020-05-12 08:36:31-04:00                    18.633540     4.285714e-01   \n",
      "2020-05-12 09:25:44-04:00                    25.925926     1.834088e+00   \n",
      "2020-05-12 09:25:56-04:00                    50.000000     7.321429e-01   \n",
      "...                                                ...              ...   \n",
      "2020-05-12 09:52:28-04:00                  -117.142857    -2.547243e+00   \n",
      "2020-05-12 09:52:31-04:00                  -100.000000     2.470658e-01   \n",
      "2020-05-12 09:52:32-04:00                   100.000000    -3.737374e-01   \n",
      "2020-05-12 09:52:35-04:00                   100.000000     5.156250e-01   \n",
      "2020-05-12 09:52:40-04:00                  -100.000000     1.421085e-12   \n",
      "\n",
      "                           forecast_mid_price  mpb_pred  buy_price  \\\n",
      "sip_timestamp                                                        \n",
      "2020-05-12 08:22:58-04:00            0.093501       1.0  34.223333   \n",
      "2020-05-12 08:27:32-04:00            0.184956      -1.0  34.060000   \n",
      "2020-05-12 08:36:31-04:00            0.200171       1.0  34.120000   \n",
      "2020-05-12 09:25:44-04:00            0.067494       1.0  34.260000   \n",
      "2020-05-12 09:25:56-04:00            0.039794       1.0  34.280000   \n",
      "...                                       ...       ...        ...   \n",
      "2020-05-12 09:52:28-04:00           -0.010215      -1.0  34.273415   \n",
      "2020-05-12 09:52:31-04:00           -0.007666      -1.0  34.270000   \n",
      "2020-05-12 09:52:32-04:00           -0.007288       1.0  34.280000   \n",
      "2020-05-12 09:52:35-04:00           -0.006483       1.0  34.280000   \n",
      "2020-05-12 09:52:40-04:00            0.004693      -1.0  34.260000   \n",
      "\n",
      "                           sell_price  shifted_bid  shifted_ask    net_pl  \n",
      "sip_timestamp                                                              \n",
      "2020-05-12 08:22:58-04:00   34.277838    34.277838    34.297027  0.054505  \n",
      "2020-05-12 08:27:32-04:00   34.296667    34.281905    34.296667 -0.236667  \n",
      "2020-05-12 08:36:31-04:00   34.274000    34.274000    34.285500  0.154000  \n",
      "2020-05-12 09:25:44-04:00   34.266286    34.266286    34.278571  0.006286  \n",
      "2020-05-12 09:25:56-04:00   34.270000    34.270000    34.287857 -0.010000  \n",
      "...                               ...          ...          ...       ...  \n",
      "2020-05-12 09:52:28-04:00         NaN          NaN          NaN       NaN  \n",
      "2020-05-12 09:52:31-04:00         NaN          NaN          NaN       NaN  \n",
      "2020-05-12 09:52:32-04:00         NaN          NaN          NaN       NaN  \n",
      "2020-05-12 09:52:35-04:00         NaN          NaN          NaN       NaN  \n",
      "2020-05-12 09:52:40-04:00         NaN          NaN          NaN       NaN  \n",
      "\n",
      "[779 rows x 16 columns]\n",
      "total P/L: -6.65651943852648\n"
     ]
    }
   ],
   "source": [
    "df = get_training_data('GDX','2020-05-11',forecast_window = 20)\n",
    "\n",
    "X_train,Y_train = prepare_nn_data(df)\n",
    "olsModel = sm.OLS(Y_train,X_train)\n",
    "results = olsModel.fit()\n",
    "#print(results.summary())\n",
    "\n",
    "\n",
    "pred_df = get_training_data('GDX','2020-05-12',forecast_window = 20)\n",
    "\n",
    "X_test,Y_test = prepare_nn_data(pred_df)\n",
    "\n",
    "ypred = pd.Series(results.predict(X_test))\n",
    "ypred.index = pred_df.index\n",
    "\n",
    "\n",
    "pred_df['mpb_pred'] = ypred\n",
    "pred_df.loc[pred_df['mpb_pred'] < 0,'mpb_pred'] = -1 # sell signal\n",
    "pred_df.loc[pred_df['mpb_pred'] > 0,'mpb_pred'] = 1 # buy signal\n",
    "pred_df['buy_price'] = 0 \n",
    "pred_df['sell_price'] = 0 \n",
    "pred_df['shifted_bid'] = pred_df['bid_price'].shift(-20)\n",
    "pred_df['shifted_ask'] = pred_df['ask_price'].shift(-20)\n",
    "\n",
    "pred_df.loc[pred_df['mpb_pred'] < 0,'buy_price'] = pred_df.loc[pred_df['mpb_pred'] < 0,'bid_price']\n",
    "pred_df.loc[pred_df['mpb_pred'] > 0,'buy_price'] = pred_df.loc[pred_df['mpb_pred'] > 0,'ask_price']\n",
    "\n",
    "pred_df.loc[pred_df['mpb_pred'] > 0,'sell_price'] = pred_df.loc[pred_df['mpb_pred'] > 0,'shifted_bid']\n",
    "pred_df.loc[pred_df['mpb_pred'] < 0,'sell_price'] = pred_df.loc[pred_df['mpb_pred'] < 0,'shifted_ask'] \n",
    "\n",
    "pred_df['net_pl'] = pred_df['sell_price']  - pred_df['buy_price'] \n",
    "pred_df.loc[pred_df['mpb_pred'] < 0,'net_pl'] *= -1\n",
    "\n",
    "print(pred_df)\n",
    "print('total P/L: {}'.format(pred_df['net_pl'].sum()))\n",
    "\n",
    "\n",
    "#nn = network()\n",
    "#nn.train_model(X_test,Y_test,num_epochs = 5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf= api.polygon.historic_agg_v2('GDX',1,'minute',_from= '2020-06-09',to='2020-06-09').df\n",
    "mdf = mdf.join(df['mpb']).resample('1S')\n",
    "print(mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 90.0 60.0\n"
     ]
    }
   ],
   "source": [
    "x = LpVariable(\"x\",0,100)\n",
    "y =LpVariable(\"y\",0,90)\n",
    "z = LpVariable(\"z\",0,70)\n",
    "\n",
    "problem = LpProblem('contracts',LpMinimize)\n",
    "problem += x + y + z == 150 \n",
    "problem += 500*x + 450*y + 450*z + 12000\n",
    "status = problem.solve()\n",
    "print(value(x),value(y),value(z),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
